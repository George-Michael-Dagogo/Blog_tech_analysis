{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from fake_useragent import UserAgent\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Punch Newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def punch_news():\n",
    "    options = Options()\n",
    "    options.headless = True\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "\n",
    "    c = DesiredCapabilities.CHROME\n",
    "    c[\"pageLoadStrategy\"] = \"none\"\n",
    "    #set chromodriver.exe path\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\HP\\Downloads\\news\\News_station_analysis\\chromedriver.exe',desired_capabilities=c,options=options)\n",
    "    #explicit wait\n",
    "    w = WebDriverWait(driver, 20)\n",
    "    #launch URL\n",
    "    driver.get(\"https://punchng.com/topics/news/\")\n",
    "    driver.implicitly_wait(20)\n",
    "    time.sleep(3)\n",
    "    #driver.implicitly_wait(20)\n",
    "    #expected condition\n",
    "    w.until(EC.presence_of_element_located((By.CLASS_NAME, 'post-title')))\n",
    "    #JavaScript Executor to stop page load\n",
    "\n",
    "    driver.execute_script(\"window.stop();\")\n",
    "    print('First huddle')\n",
    "\n",
    "    content = []\n",
    "    contents =driver.find_elements_by_class_name(\"post-title\")\n",
    "    for con in contents:\n",
    "        cont = con.get_attribute('innerHTML')\n",
    "        content.append(cont)\n",
    "    af = pd.DataFrame(content,columns =['content'])\n",
    "    af.content = af.content.apply(lambda x: x.replace('<a href=', ''))\n",
    "    af.content = af.content.apply(lambda x: x.replace('</a>', ''))\n",
    "    af.content = af.content.apply(lambda x: x.replace('>', '|'))\n",
    "    af = af['content'].str.split(\"|\",n = 3, expand = True)\n",
    "    af.columns = ['link','title']\n",
    "    af = af.drop_duplicates(subset=[\"link\"], keep='first')\n",
    "    print('Second huddle')\n",
    "    full_contents = []\n",
    "    dates = []\n",
    "    by = []\n",
    "    def all_news(ev):\n",
    "        h = WebDriverWait(driver, 20)\n",
    "        full = []\n",
    "        timed = []\n",
    "        print('Pages extraction in progress')\n",
    "\n",
    "        driver.get(ev)\n",
    "        time.sleep(4)\n",
    "        driver.implicitly_wait(20)\n",
    "        h.until(EC.presence_of_element_located((By.CLASS_NAME, 'post-content')))\n",
    "        #JavaScript Executor to stop page load\n",
    "        driver.execute_script(\"window.stop();\")\n",
    "        full_content = driver.find_elements_by_class_name(\"post-content\")\n",
    "        for conten in full_content:\n",
    "            co = conten.get_attribute('innerText')\n",
    "            co1 = co.replace('\\n\\n',' ')\n",
    "            co2 = co1.replace('\\n',' ')\n",
    "            co3 = co2.split(',', 1)\n",
    "            full.append(co3)\n",
    "\n",
    "        date = driver.find_elements_by_class_name(\"col-lg-4\")\n",
    "        for dat in date:\n",
    "            dat1= dat.get_attribute('innerText')\n",
    "            dat2 = dat1.replace('By\\xa0\\n','')\n",
    "            timed.append(dat2)\n",
    "        full_contents.append(full[0])\n",
    "        dates.append(timed[0])\n",
    "        by.append(timed[1])\n",
    "\n",
    "    m =af.link.to_list()\n",
    "    m =  [item.replace('\"', '') for item in m]\n",
    "    for o in m:\n",
    "        all_news(o)\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "    aa = pd.DataFrame({'Title':af.title,'Full_content': full_contents,'Date':dates,'Author':by,'Source_link':af.link})\n",
    "    ff  =aa['Full_content'].apply(lambda x: ' '.join(dict.fromkeys(x).keys()))#unlist the full_content column\n",
    "\n",
    "    aa['Words_count'] = ff.str.split().str.len()#counts the full_content\n",
    "    n = open(\"negative-words.txt\", \"r\")\n",
    "    p = open(\"positive-words.txt\", \"r\")\n",
    "    n_word = n.read()\n",
    "    p_word = p.read()\n",
    "    n.close()\n",
    "    p.close()\n",
    "    n_word=n_word.replace('\\n',',')\n",
    "    n_word = re.sub(\"[^\\w]\", \" \", n_word).split()\n",
    "    p_word=p_word.replace('\\n',',')\n",
    "    p_word = re.sub(\"[^\\w]\", \" \", p_word).split()\n",
    "    aa['Full_content'] = ff\n",
    "    #df['word_overlap'] = [set(x[0].split()) & set(x[1].split()) for x in df.values]\n",
    "    def negative_words(x):\n",
    "        negative_score = 0\n",
    "        for word in n_word:\n",
    "            if word in x:\n",
    "                negative_score += 1\n",
    "        return negative_score\n",
    "\n",
    "    def positive_words(x):\n",
    "        positive_score = 0\n",
    "        for word in p_word:\n",
    "            if word in x:\n",
    "                positive_score += 1\n",
    "        return positive_score\n",
    "    aa['Negative_words'] = aa['Full_content'].apply(lambda x : negative_words(x))\n",
    "    aa['Positive_words'] = aa['Full_content'].apply(lambda x : positive_words(x))\n",
    "    aa['Sentence_count'] = aa['Full_content'].str.count('[\\w][\\.!\\?]')\n",
    "    aa['Sentiment'] = round((aa['Positive_words'] - aa['Negative_words']) / aa['Words_count'], 2)\n",
    "    aa['News_type'] = ['Bad News' if x < 0 else 'Good News' if x > 0 else 'Neutral' for x in aa.Sentiment]\n",
    "    engine = create_engine('sqlite:///news.db')\n",
    "    aa.to_sql('punch_data', engine, if_exists='append', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First huddle\n",
      "Second huddle\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n"
     ]
    }
   ],
   "source": [
    "punch_news()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanguard Newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanguard_news():\n",
    "    options = Options()\n",
    "    ua = UserAgent()\n",
    "    userAgent = ua.random\n",
    "    options.add_argument(f'user-agent={userAgent}')\n",
    "    options.headless = True\n",
    "    c = DesiredCapabilities.CHROME\n",
    "    c[\"pageLoadStrategy\"] = \"none\"\n",
    "    #set chromodriver.exe path\n",
    "\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\HP\\Downloads\\news\\News_station_analysis\\chromedriver.exe',desired_capabilities=c,options=options)\n",
    "    #explicit wait\n",
    "\n",
    "    driver.get(\"https://www.vanguardngr.com/news/\")\n",
    "    #explicit wait\n",
    "    w = WebDriverWait(driver, 20)\n",
    "    #launch URL\n",
    "    #driver.get(\"https://www.vanguardngr.com/category/headlines/\")\n",
    "    driver.implicitly_wait(20)\n",
    "    time.sleep(3)\n",
    "    #driver.implicitly_wait(20)\n",
    "    #expected condition\n",
    "    w.until(EC.presence_of_element_located((By.CLASS_NAME, 'entry-title')))\n",
    "    #JavaScript Executor to stop page load\n",
    "\n",
    "    driver.execute_script(\"window.stop();\")\n",
    "    print('First huddle')\n",
    "\n",
    "    content = []\n",
    "    contents =driver.find_elements_by_class_name(\"entry-title\")\n",
    "    for con in contents:\n",
    "        cont = con.get_attribute('innerHTML')\n",
    "        content.append(cont)\n",
    "\n",
    "    af = pd.DataFrame(content,columns =['content'])\n",
    "    af.content = af.content.apply(lambda x: x.replace('<a href=\"', ''))\n",
    "    af = af.iloc[1:]\n",
    "    af = af.reset_index()\n",
    "    af.content = af.content.apply(lambda x: x.replace('rel=\"bookmark\">', ' | '))\n",
    "    af.content = af.content.apply(lambda x: x.replace('</a>', ' '))\n",
    "    af = af['content'].str.split(\"|\",n = 3, expand = True)\n",
    "    af.columns = ['News_link','Title']\n",
    "    sd = af.head(20)\n",
    "    driver.quit()\n",
    "    full_contents = []\n",
    "    dates = []\n",
    "    datetime = []\n",
    "    genres = []\n",
    "    def all_news(ev):\n",
    "        options = Options()\n",
    "        options.headless = True\n",
    "        ua = UserAgent()\n",
    "        userAgent = ua.random\n",
    "        options.page_load_strategy = 'eager'\n",
    "        options.add_argument(f'user-agent={userAgent}')\n",
    "        driver = webdriver.Chrome(r'C:\\Users\\HP\\Downloads\\news\\News_station_analysis\\chromedriver.exe',options=options)\n",
    "        driver.get(ev)\n",
    "        driver.implicitly_wait(20)\n",
    "        time.sleep(10)\n",
    "\n",
    "        full_content = driver.find_elements_by_class_name(\"entry-content\")\n",
    "        for conten in full_content:\n",
    "            co = conten.get_attribute('innerText')\n",
    "            co1 = co.replace('\\n\\n','')\n",
    "            co2 = co1.replace('Subscribe for latest Videos','')\n",
    "            #co3 = co2[co2.find('|'):] #deletes anything before the |\n",
    "            co3 = co2.replace('\\n',' ')\n",
    "            co4 = co3.split(',',1)\n",
    "            full_contents.append(co4)\n",
    "\n",
    "        date = driver.find_elements_by_class_name(\"entry-date.published.updated\")\n",
    "        for dat in date:\n",
    "            date= dat.get_attribute('innerText')\n",
    "            dates.append(date)\n",
    "            tim= dat.get_attribute('dateTime')\n",
    "            datetime.append(tim)\n",
    "\n",
    "        genre = driver.find_elements_by_xpath(\"\"\"//*[@id=\"main\"]/header/span/a\"\"\")\n",
    "        for gen in genre:\n",
    "            gen1= gen.get_attribute('innerText')\n",
    "            #gen2 = gen1.replace('POSTED IN\\n','')\n",
    "            genres.append(gen1)\n",
    "        print('going')\n",
    "        driver.quit()\n",
    "\n",
    "    a = sd.News_link.to_list()\n",
    "    a =  [item.replace('\"  ', '') for item in a]\n",
    "    #a = ['https://www.vanguardngr.com/2022/12/mavins-marks-10th-anniversary-with-new-album/']\n",
    "    for i in a:\n",
    "        all_news(i)\n",
    "\n",
    "    ss = pd.DataFrame({'Full_content': full_contents,'Date':dates,'Time_published':datetime})\n",
    "    ff  =ss['Full_content'].apply(lambda x: ' '.join(dict.fromkeys(x).keys()))\n",
    "\n",
    "    ss['Words_count'] = ff.str.split().str.len()\n",
    "    n = open(\"negative-words.txt\", \"r\")\n",
    "    p = open(\"positive-words.txt\", \"r\")\n",
    "    n_word = n.read()\n",
    "    p_word = p.read()\n",
    "    n.close()\n",
    "    p.close()\n",
    "    n_word=n_word.replace('\\n',',')\n",
    "    n_word = re.sub(\"[^\\w]\", \" \", n_word).split()\n",
    "    p_word=p_word.replace('\\n',',')\n",
    "    p_word = re.sub(\"[^\\w]\", \" \", p_word).split()\n",
    "    #df['word_overlap'] = [set(x[0].split()) & set(x[1].split()) for x in df.values]\n",
    "    def negative_words(x):\n",
    "        negative_score = 0\n",
    "        for word in n_word:\n",
    "            if word in x:\n",
    "                negative_score += 1\n",
    "        return negative_score\n",
    "\n",
    "    def positive_words(x):\n",
    "        positive_score = 0\n",
    "        for word in p_word:\n",
    "            if word in x:\n",
    "                positive_score += 1\n",
    "        return positive_score\n",
    "    ss['Full_content'] = ff\n",
    "    ss['News_genre'] = genres\n",
    "    ss['Negative_words'] = ss['Full_content'].apply(lambda x : negative_words(x))\n",
    "    ss['Positive_words'] = ss['Full_content'].apply(lambda x : positive_words(x))\n",
    "    ss['Sentence_count'] = ss['Full_content'].str.count('[\\w][\\.!\\?]')\n",
    "\n",
    "    ss['Sentiment'] = round((ss['Positive_words'] - ss['Negative_words']) / ss['Words_count'], 2)\n",
    "    ss['News_type'] = ['Bad News' if x < 0 else 'Good News' if x > 0 else 'Neutral' for x in ss.Sentiment]\n",
    "    va = pd.concat([sd,ss], axis=1)\n",
    "    engine = create_engine('sqlite:///news.db')\n",
    "    va.to_sql('vanguard_data', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First huddle\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n",
      "going\n"
     ]
    }
   ],
   "source": [
    "vanguard_news()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Nation Newspaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First huddle\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n",
      "Pages extraction in progress\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Full_content</th>\n",
       "      <th>Date</th>\n",
       "      <th>Author</th>\n",
       "      <th>News_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soludo, Obi, Obiano reunite as Cardinal Arinze...</td>\n",
       "      <td>It was a kind of reunion between Anambra Gover...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Nwanosike Onu, Awka and Emma Elekwa, Onitsha</td>\n",
       "      <td>https://thenationonlineng.net/soludo-obi-obian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rivers, Atiku’s campaigner bicker over gunmen ...</td>\n",
       "      <td>The Rivers State Government and chairman of th...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Mike Odiegwu, Port Harcourt</td>\n",
       "      <td>https://thenationonlineng.net/rivers-atikus-ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘Buhari will leave Nigeria better than he met it’</td>\n",
       "      <td>The Chief of Staff to the President, Prof. Ibr...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Agency Reporter</td>\n",
       "      <td>https://thenationonlineng.net/buhari-will-leav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No going back on cash withdrawal limit policy ...</td>\n",
       "      <td>The Central Bank of Nigeria (CBN) has stated t...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Bolaji Ogundele, Abuja</td>\n",
       "      <td>https://thenationonlineng.net/no-going-back-on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reps summon Emefiele over cash withdrawal policy</td>\n",
       "      <td>The House of Representatives on Thursday summo...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Agency Reporter</td>\n",
       "      <td>https://thenationonlineng.net/updated-reps-sum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>953,803 PVCs uncollected in Lagos, says INEC</td>\n",
       "      <td>The Independent National Electoral Commission ...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Agency Reporter</td>\n",
       "      <td>https://thenationonlineng.net/953803-pvcs-unco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I won’t be distracted, says Wike</td>\n",
       "      <td>Rivers Governor Nyesom Wike has vowed that not...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Mike Odiegwu, Port Harcourt</td>\n",
       "      <td>https://thenationonlineng.net/i-wont-be-distra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Court dismisses suit challenging Adeola’s Ogun...</td>\n",
       "      <td>AFederal High Court sitting in Abeokuta, the O...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Ernest Nwokolo, Abeokuta</td>\n",
       "      <td>https://thenationonlineng.net/court-dismisses-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gunmen whisk away four new babies in Soludo’s ...</td>\n",
       "      <td>Gunmen in the early hours of Thursday allegedl...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Nwanosike Onu, Awka</td>\n",
       "      <td>https://thenationonlineng.net/gunmen-whisk-awa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Supreme Court dismisses appeal against PDP’s I...</td>\n",
       "      <td>The Supreme Court has dismissed an appeal agai...</td>\n",
       "      <td>December 8, 2022</td>\n",
       "      <td>Eric Ikhilae, Abuja</td>\n",
       "      <td>https://thenationonlineng.net/supreme-court-di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Soludo, Obi, Obiano reunite as Cardinal Arinze...   \n",
       "1  Rivers, Atiku’s campaigner bicker over gunmen ...   \n",
       "2  ‘Buhari will leave Nigeria better than he met it’   \n",
       "3  No going back on cash withdrawal limit policy ...   \n",
       "4   Reps summon Emefiele over cash withdrawal policy   \n",
       "5       953,803 PVCs uncollected in Lagos, says INEC   \n",
       "6                   I won’t be distracted, says Wike   \n",
       "7  Court dismisses suit challenging Adeola’s Ogun...   \n",
       "8  Gunmen whisk away four new babies in Soludo’s ...   \n",
       "9  Supreme Court dismisses appeal against PDP’s I...   \n",
       "\n",
       "                                        Full_content               Date  \\\n",
       "0  It was a kind of reunion between Anambra Gover...   December 8, 2022   \n",
       "1  The Rivers State Government and chairman of th...   December 8, 2022   \n",
       "2  The Chief of Staff to the President, Prof. Ibr...   December 8, 2022   \n",
       "3  The Central Bank of Nigeria (CBN) has stated t...   December 8, 2022   \n",
       "4  The House of Representatives on Thursday summo...   December 8, 2022   \n",
       "5  The Independent National Electoral Commission ...   December 8, 2022   \n",
       "6  Rivers Governor Nyesom Wike has vowed that not...   December 8, 2022   \n",
       "7  AFederal High Court sitting in Abeokuta, the O...   December 8, 2022   \n",
       "8  Gunmen in the early hours of Thursday allegedl...   December 8, 2022   \n",
       "9  The Supreme Court has dismissed an appeal agai...   December 8, 2022   \n",
       "\n",
       "                                          Author  \\\n",
       "0  Nwanosike Onu, Awka and Emma Elekwa, Onitsha    \n",
       "1                   Mike Odiegwu, Port Harcourt    \n",
       "2                               Agency Reporter    \n",
       "3                        Bolaji Ogundele, Abuja    \n",
       "4                               Agency Reporter    \n",
       "5                               Agency Reporter    \n",
       "6                   Mike Odiegwu, Port Harcourt    \n",
       "7                      Ernest Nwokolo, Abeokuta    \n",
       "8                           Nwanosike Onu, Awka    \n",
       "9                           Eric Ikhilae, Abuja    \n",
       "\n",
       "                                           News_link  \n",
       "0  https://thenationonlineng.net/soludo-obi-obian...  \n",
       "1  https://thenationonlineng.net/rivers-atikus-ca...  \n",
       "2  https://thenationonlineng.net/buhari-will-leav...  \n",
       "3  https://thenationonlineng.net/no-going-back-on...  \n",
       "4  https://thenationonlineng.net/updated-reps-sum...  \n",
       "5  https://thenationonlineng.net/953803-pvcs-unco...  \n",
       "6  https://thenationonlineng.net/i-wont-be-distra...  \n",
       "7  https://thenationonlineng.net/court-dismisses-...  \n",
       "8  https://thenationonlineng.net/gunmen-whisk-awa...  \n",
       "9  https://thenationonlineng.net/supreme-court-di...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options = Options()\n",
    "#options.headless = True\n",
    "ua = UserAgent()\n",
    "userAgent = ua.random\n",
    "options.add_argument(f'user-agent={userAgent}')\n",
    "\n",
    "c = DesiredCapabilities.CHROME\n",
    "c[\"pageLoadStrategy\"] = \"none\"\n",
    "#set chromodriver.exe path\n",
    "driver = webdriver.Chrome(r'C:\\Users\\HP\\Downloads\\news\\News_station_analysis\\chromedriver.exe',desired_capabilities=c,options=options)\n",
    "#explicit wait\n",
    "w = WebDriverWait(driver, 20)\n",
    "#launch URL\n",
    "driver.get(\"https://thenationonlineng.net/news/\")\n",
    "driver.implicitly_wait(20)\n",
    "\n",
    "#driver.implicitly_wait(20)\n",
    "#expected condition\n",
    "w.until(EC.presence_of_element_located((By.CLASS_NAME, 'nation_category_post_title')))\n",
    "#JavaScript Executor to stop page load\n",
    "\n",
    "driver.execute_script(\"window.stop();\")\n",
    "print('First huddle')\n",
    "\n",
    "content = []\n",
    "contents =driver.find_elements_by_css_selector('section section a')\n",
    "for con in contents:\n",
    "    cont = con.get_attribute('href')\n",
    "    content.append(cont)\n",
    "\n",
    "af = pd.DataFrame(content,columns =['content'])\n",
    "af = af.drop_duplicates(subset=[\"content\"], keep='first')\n",
    "#af = af[af[\"content\"].str.contains(\"https://thenationonlineng.net/news/page/2/\") == False]\n",
    "discard = [\"https://thenationonlineng.net/news/page/\"]\n",
    "  \n",
    "# drop rows that contain the partial string \"Sci\"\n",
    "af = af[~af.content.str.contains('|'.join(discard))]\n",
    "titless = []\n",
    "by = []\n",
    "date = []\n",
    "full_content = []\n",
    "\n",
    "def all_news(ev):\n",
    "    h = WebDriverWait(driver, 20)\n",
    "    driver.get(ev)\n",
    "    time.sleep(5)\n",
    "    driver.implicitly_wait(20)\n",
    "    h.until(EC.presence_of_element_located((By.CLASS_NAME, 'nation__article__content')))\n",
    "    #JavaScript Executor to stop page load\n",
    "    driver.execute_script(\"window.stop();\")\n",
    "    title = driver.find_elements_by_css_selector('section article header h1')\n",
    "    for tit in title:\n",
    "        titl = tit.get_attribute('innerText')\n",
    "        titless.append(titl)\n",
    "\n",
    "    who = driver.find_elements_by_class_name(\"nation__article__meta\")\n",
    "    for wh in who:\n",
    "        w = wh.get_attribute('outerText')\n",
    "        w = w.replace('\\n',' | ')\n",
    "        w = w.split('|',1)\n",
    "\n",
    "        by.append(w[0])\n",
    "        date.append(w[1])\n",
    "    print('Pages extraction in progress')\n",
    "    article = driver.find_elements_by_class_name('nation__article__content')\n",
    "    for art in article:\n",
    "        arti = art.get_attribute('innerText')\n",
    "        arti = arti.replace('\\n\\n','')\n",
    "        arti = arti.split('ADVERTISEMENTS')[0]\n",
    "        full_content.append(arti)\n",
    "        \n",
    "for i in af.content:\n",
    "    all_news(i)\n",
    "driver.quit()  \n",
    "ss = pd.DataFrame({'Title': titless,'Full_content': full_content,'Date':date,'Author':by,'News_link':af.content})\n",
    "ss['Words_count'] = ss.Full_content.str.split().str.len()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = open(\"negative-words.txt\", \"r\")\n",
    "p = open(\"positive-words.txt\", \"r\")\n",
    "n_word = n.read()\n",
    "p_word = p.read()\n",
    "n.close()\n",
    "p.close()\n",
    "n_word=n_word.replace('\\n',',')\n",
    "n_word = re.sub(\"[^\\w]\", \" \", n_word).split()\n",
    "p_word=p_word.replace('\\n',',')\n",
    "p_word = re.sub(\"[^\\w]\", \" \", p_word).split()\n",
    "def negative_words(x):\n",
    "    negative_score = 0\n",
    "    for word in n_word:\n",
    "        if word in x:\n",
    "            negative_score += 1\n",
    "    return negative_score\n",
    "\n",
    "def positive_words(x):\n",
    "    positive_score = 0\n",
    "    for word in p_word:\n",
    "        if word in x:\n",
    "            positive_score += 1\n",
    "    return positive_score\n",
    "\n",
    "ss['Negative_words'] = ss['Full_content'].apply(lambda x : negative_words(x))\n",
    "ss['Positive_words'] = ss['Full_content'].apply(lambda x : positive_words(x))\n",
    "ss['Sentence_count'] = ss['Full_content'].str.count('[\\w][\\.!\\?]')\n",
    "\n",
    "ss['Sentiment'] = round((ss['Positive_words'] - ss['Negative_words']) / ss['Words_count'], 2)\n",
    "ss['News_type'] = ['Bad News' if x < 0 else 'Good News' if x > 0 else 'Neutral' for x in ss.Sentiment]\n",
    "engine = create_engine('sqlite:///news.db')\n",
    "ss.to_sql('nation_newspaper_data', engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
